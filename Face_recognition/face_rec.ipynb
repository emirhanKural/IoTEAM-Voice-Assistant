{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "friendly-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename.jpg  is being encoded\n",
      "JohnHammond.jpg  is being encoded\n",
      "nefise2.jpg  is being encoded\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "nefise2\n",
      "All predictions: ['nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2', 'nefise2']\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "known_person=[] #Name of person string\n",
    "known_image=[] #Image object\n",
    "known_face_encodings=[] #Encoding object\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "#Loop to add images in family folder\n",
    "for file in os.listdir(\"profiles\"):\n",
    "    if file.split(\".\")[-1]== \"jpg\":\n",
    "        try:\n",
    "            print(file,\" is being encoded\")\n",
    "            known_person.append(file.replace(\".jpg\", \"\"))#Extracting person name\n",
    "            file=os.path.join(\"profiles/\", file)\n",
    "            known_image = face_recognition.load_image_file(file)\n",
    "            known_face_encodings.append(face_recognition.face_encodings(known_image)[0])\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "#print(len(known_face_encodings))\n",
    "#print(known_person)\n",
    "\n",
    "capture_duration = 10 # set time limit to this capture\n",
    "start_time = time.time()\n",
    "while( int(time.time() - start_time) < capture_duration ):\n",
    "\n",
    "    ret, frame = video_capture.read()\n",
    "    #frame = cv2.flip(frame, -1) #turn 180 degree\n",
    "\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    \n",
    "    if process_this_frame:\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        \n",
    "        global name_gui;\n",
    "        for face_encoding in face_encodings:\n",
    "            \n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_person[best_match_index]\n",
    "                print(name)\n",
    "            face_names.append(name)\n",
    "    \n",
    "            name_gui = name\n",
    "    \n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "    \n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (255, 255, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name_gui, (left + 10, bottom - 10), font, 1.0, (0, 0, 0), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Hit 'q' or Esc on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "print(\"All predictions:\",face_names)\n",
    "    \n",
    "\n",
    "#from picamera import PiCamera\n",
    "#from time import sleep\n",
    "\n",
    "#def take_photo():\n",
    "#    camera = PiCamera()\n",
    "#    camera.resolution = (640,480)\n",
    "#    camera.resolution = (640,480)\n",
    "#    camera.start_preview()\n",
    "#    sleep(5)\n",
    "#    camera.capture('/home/pi/Documents/face_pi/profiles/add_user_name.jpg')\n",
    "#    camera.stop_preview()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import *\n",
    "# initialize the camera\n",
    "cam = VideoCapture(0)   # 0 -> index of camera\n",
    "s, img = cam.read()\n",
    "if s:    # frame captured without any errors\n",
    "    namedWindow(\"cam-test\")\n",
    "    imshow(\"cam-test\",img)\n",
    "    waitKey(0)\n",
    "    destroyWindow(\"cam-test\")\n",
    "    imwrite(\"profiles/filename.jpg\",img) #save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-replication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
